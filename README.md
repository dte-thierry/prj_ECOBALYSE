<a name="debut" />

<img src="img/PRJ-ECOBALYSE-00-LOGO.png" alt="Logo DataScientest" style="width:250px;height:auto;">

# Datascientest: [projet EcoBalyse](./PRJ-ECOBALYSE-00-FICHE_PROJET.pdf) (Nov. 2024)
> *Data Engineering End-to-End Project : AirFlow, Dash, Flask, Docker, Redis, MongoDB, Python* <br />

Derni√®re Mise A Jour du Document : Mer. 06/11/2024 - Version : v0.2.0

## [Sommaire](#debut)
- [Contexte](#tdm-01)
- [Pr√©sentation](#tdm-02)
    - [Etapes du projet](#tdm-02-01)
- [Mode d'emploi](#tdm-03)
    - [Pr√©-requis (`./info.sh` | `./mode.sh` | `./starter.sh`)](#tdm-03-01)
    - [(R√©)Initialiser (`./init.sh`)](#tdm-03-02)
    - [(Re)Configurer (`./setup.sh`)](#tdm-03-03)
    - [(Re)Charger (`./load.sh`)](#tdm-03-04)
- [Solution technique](#tdm-05)
    - [Sch√©ma de Principe](#tdm-05-01)
    - [Dossiers & R√©pertoires](#tdm-05-02)
- [D√©tails techniques](#tdm-07)
    - [Architecture](#tdm-07-07)
    - [ETL](#tdm-07-01)
    - [MongoDB](#tdm-07-02)
    - [Redis](#tdm-07-03)
    - [Flask](#tdm-07-04)
    - [Dash](#tdm-07-05)
    - [AirFlow](#tdm-07-06)
- [A propos d'Ecobalyse](#tdm-06)

## <a name="tdm-01" />[Contexte](#debut)
Ce projet a √©t√© r√©alis√© dans le cadre de la <b>formation Data Engineer</b>, propos√©e par :  
<a href="https://datascientest.com/formation-data-engineer" target="_blank">Datascientest, et l'Ecole des Mines ParisTech</a>.

Le *[cursus p√©dagogique](./img/DATASCIENTEST_ParcoursPedagogique.png)* de la <b>formation Data Engineer</b> s'inscrit dans le cadre de la **[certification n¬∞RNCP36129](https://www.francecompetences.fr/recherche/rncp/36129/)** :  
*‚ÄúChef de projet en intelligence artificielle / (Machine Learning Engineer)‚Äù, Niveau 7 (bac + 5)*.  

L'√©quipe ayant r√©alis√© ce projet se compose de :
* SERDYUK Alexandra
* BENALLEGUE Anis
* DELIGNE Thierry

Le **Rapport Final**, expliquant tout le workflow d√©cisionnel du projet, est disponible : [ici](./ecblRapport.pdf).

## <a name="tdm-02" />[Pr√©sentation](#debut)
Bas√© sur les donn√©es, et l'`API` de calcul des impacts environnementaux d'[Ecobalyse v2.4.0](https://ecobalyse.beta.gouv.fr/), ce projet doit permettre : 
- d'obtenir une √©valuation de l'impact √©cologique de textiles courants
- de fournir des recommandations ou des conseils sur des alternatives plus durables

<br />
<img src="img/PRJ-ECOBALYSE-00-IMG2.jpg" alt="Pr√©sentation" style="width:750px;height:auto;">

### <a name="tdm-02-01" />[Etapes du projet](#tdm-02)

> üí¨ **Nota : Par d√©faut, la r√©colte des donn√©es se fait en mode `Basic`.** <br />
> Lancer le script `./mode.sh -f` pour d√©finir une r√©colte des donn√©es en mode `Complet`.

- **Etape 01 : r√©colte des donn√©es** <br />
[Extraction](notebooks/PRJ-ECOBALYSE-01-ETAPE-01-BASIC_v0-20.ipynb) (mode `Basic`), [Transformation](notebooks/PRJ-ECOBALYSE-02-ETAPE-01-FULL_v0-20.ipynb) (mode `Complet`)

    - Identification de la source de donn√©es
    - Connexion et importation des donn√©es

- **Etape 02 : architecture & stockage**

    - Choix d'un SGBD adapt√© au probl√®me
    - Mod√©lisation des tables/collections/index

- **Etape 03 : consommation des donn√©es** <br />
`Visualisations` (mode: [Basic](notebooks/PRJ-ECOBALYSE-03-ETAPE-03-VISU-BASIC_v0-20.ipynb) | [Complet](notebooks/PRJ-ECOBALYSE-04-ETAPE-03-VISU-FULL_v0-20.ipynb)) , `Pr√©dictions` (mode: [Basic](notebooks/PRJ-ECOBALYSE-05-ETAPE-03-ML-BASIC_v0-20.ipynb) | [Complet](notebooks/PRJ-ECOBALYSE-06-ETAPE-03-ML-FULL_v0-20.ipynb))

    - Dashboard ou Algorithme de Machine Learning (p√©rim√®tre du *Data Scientist/Analyst*)

- **Etape 04 : mise en production**

    - Cr√©ation de l'API du projet
    - Dockerisation de tout le projet

- **Etape 05 : automatisation des flux (<i>Etape facultative</i>)**

    - Automatisation des t√¢ches avec AirFlow

## <a name="tdm-03" />[Mode d'emploi](#debut)

### <a name="tdm-03-01" />[Pr√©-requis (`./info.sh` | `./mode.sh` | `./starter.sh`)](#tdm-03)

| üí¨ Avertissement ! Le client Docker doit √™tre install√© sur la machine virtuelle. |
|----------|
| Pour (r√©)installer, ou mettre √† jour le client **Docker**, consulter le fichier [lisezMoi.txt](./lisezMoi.txt). | 

> üí¨ **Nota : action pr√©alable facultative √† l'extraction des donn√©es Ecobalyse** <br />
> Une fois le d√©p√¥t GitHub recopi√©, vous pouvez sp√©cifier le **mode d'extraction des donn√©es** *(Basic | Complet)* depuis le script :
> `./mode.sh`.

> **R√©sum√© du(des) script(s) utile(s)**
>
> - `./info.sh -v` # affiche la version du client Docker install√© (nota: ./info.sh <b>-?</b> renvoie les options disponibles)
> - `./info.sh -i` # affiche la liste des images Docker pr√©sentes 
> - `./info.sh -a` # affiche la liste des conteneurs Docker actifs
> - `./info.sh -df` # affiche l'espace disque disponible
>
> **R√©sum√© du(des) script(s) facultatif(s)**
>
> - `./mode.sh -f` # configure le mode d'extraction **(Complet)** des donn√©es Ecobalyse. Fixe le nombre de donn√©es al√©atoires, par cat√©gories de textiles.
> - `./mode.sh` # configure le mode d'extraction **(Basic)** des donn√©es Ecobalyse. 
> - `./starter.sh -i` # v√©rifie l'extraction des Donn√©es Ecobalyse (nota: ./starter.sh <b>-?</b> renvoie les options disponibles)
> - `./starter.sh` # idem : v√©rifie l'extraction des Donn√©es Ecobalyse

#### Configurer VS Code

- installer [VS Code](https://code.visualstudio.com/) localement sur votre PC, en fonction de votre syst√®me d'exploitation.

- configurer [VS Code](https://code.visualstudio.com/) pour pouvoir acc√©der, via <i>SSH</i>, √† la machine virtuelle DataSientest.

#### Lancer la machine virtuelle

- acc√©der, puis lancer la machine virtuelle DataScientest, depuis le lien : <br /> `https://learn.datascientest.com/lesson/349/3682`

#### Recopier le d√©p√¥t Github

- recopier le d√©p√¥t GitHub sur la machine virtuelle, par la commande : <br /> `git clone https://github.com/dte-thierry/prj_ECOBALYSE.git`

#### V√©rifier la version  

- au besoin, depuis le r√©pertoire <i><b>~/prj_ECOBALYSE</i></b>, une fois le d√©p√¥t GitHub recopi√©, lancer le script : <br />
`./info.sh -v`, pour v√©rifier la version du client Docker install√©. (nota: `./info.sh -?` renvoie les options disponibles)

#### üí¨ Facultatif 

- Le mode d'extraction des donn√©es (Basic | Complet) **peut √™tre choisi au pr√©alable** de l'extraction <i>"standard" des donn√©es</i> Ecobalyse. Lancer le script `./mode.sh`, pour pr√©ciser votre choix. (nota: `./mode.sh -?` renvoie les options disponibles)

- puis, depuis le r√©pertoire <i><b>~/prj_ECOBALYSE</i></b>, lancer le script `./starter.sh -i` pour tester l'extraction <i>"standard"</i> (hors conteneur **Docker**) des donn√©es Ecobalyse.
  
- via [VS Code](https://code.visualstudio.com/), depuis le r√©pertoire */logs*, consulter le contenu du fichier `'manual_webscraping_(date).log'`, pour v√©rifier le r√©sultat obtenu.

##### üí¨ Nota 

Vous pouvez lancer le script `./starter.sh`, <b>sans aucune option</b>. 

En lan√ßant le script `./starter.sh -i`, en fonction du **mode d'extraction des donn√©es** (Basic | Complet), vous obtiendrez les messages d'avertissement suivants :

###### Mode Basic

```bash
--------------------------------------------------------------
ETAPE 01 : R√©cup√©ration des Donn√©es via l'API Ecobalyse v2.4.0
--------------------------------------------------------------
VM utilis√©e, √† l'adresse IP / SSH publique : 54.154.13.241

Mode d'Extraction Des Donn√©es : Basic. 
Fichier JSON √† cr√©er : PRJ-ECOBALYSE-TEXTILES_basic.json

Avertissement:
--------------
L'API d'Ecobalyse est actuellement non finalis√©e, toujours en cours de d√©veloppement.
Ce projet se base sur l'API d'Ecobalyse : v2.4.0 pour r√©cup√©rer les donn√©es.
Soyez attentif et vigilant √† la r√©cup√©ration des donn√©es Ecobalyse obtenues, via l'API.
Consultez dans le r√©pertoire /logs, le fichier .log : (manual|docker)_webscraping_(aaaa-mm-jj_hh-mn).log.
V√©rifiez qu'aucune description de textile (colonne 'description') ne soit de type : NaN


DataFrame, fichiers 'log' et 'json' PRJ-ECOBALYSE-TEXTILES_basic.json cr√©√©s avec succ√®s, en mode basic.
```

###### Mode Complet

```bash
--------------------------------------------------------------
ETAPE 01 : R√©cup√©ration des Donn√©es via l'API Ecobalyse v2.4.0
--------------------------------------------------------------
VM utilis√©e, √† l'adresse IP / SSH publique : 54.154.13.241

Mode d'Extraction Des Donn√©es : Complet, avec ajout et transformation de donn√©es al√©atoires. 
Fichier JSON √† cr√©er : PRJ-ECOBALYSE-TEXTILES_full.json

Avertissement:
--------------
L'API d'Ecobalyse est actuellement non finalis√©e, toujours en cours de d√©veloppement.
Ce projet se base sur l'API d'Ecobalyse : v2.4.0 pour r√©cup√©rer les donn√©es.
Soyez attentif et vigilant √† la r√©cup√©ration des donn√©es Ecobalyse obtenues, via l'API.
Consultez dans le r√©pertoire /logs, le fichier .log : (manual|docker)_webscraping_(aaaa-mm-jj_hh-mn).log.
V√©rifiez qu'aucune description de textile (colonne 'description') ne soit de type : NaN


DataFrame, fichiers 'log' et 'json' PRJ-ECOBALYSE-TEXTILES_full.json cr√©√©s avec succ√®s, en mode complet.
```

### <a name="tdm-03-02" />[(R√©)Initialiser (`./init.sh`)](#tdm-03)

> **R√©sum√© du(des) script(s) utile(s)**
>
> - `./init.sh` # supprime toutes les donn√©es (si elles existent) et (r√©)initialise totalement la configuration du projet

#### Supprimer les conteneurs

Depuis le r√©pertoire <i><b>~/prj_ECOBALYSE</i></b> :

- lancer le script `./init.sh` pour supprimer toutes les donn√©es (*logs* et *json*), et tous les conteneurs, images, volumes, r√©seaux inutilis√©s.

### <a name="tdm-03-03" />[(Re)Configurer (`./setup.sh`)](#tdm-03)

> **R√©sum√© du(des) script(s) utile(s)**
>
> - `./setup.sh` # supprime les fichiers *.log*, et (re)lance les diff√©rents conteneurs du projet 
> - `./info.sh -logs` # visualise les logs des conteneurs actifs : *ecblwebscraping* , *ecblmongodb* , *ecblredis* 
>
> **R√©sum√© du(des) script(s) facultatif(s)**
>
> - `./setup.sh -json` # supprime les fichiers *.log*, **les fichiers *.json*,** et (re)lance les diff√©rents conteneurs du projet 

#### Lancer les services

- lancer le script `./setup.sh` pour supprimer les fichiers *.log*, et (re)lancer les diff√©rents conteneurs du projet.

#### Visualiser les logs des conteneurs actifs

- puis, lancer le script `./info.sh -logs` pour visualiser les logs des conteneurs (re)lanc√©s : *ecblwebscraping* , *ecblmongodb* , *ecblredis*.

#### Consulter les fichiers .log

- via [VS Code](https://code.visualstudio.com/), consulter le contenu des fichiers .log, pour v√©rifier que l'environnement de stockage `MongoDB` / `Redis` est fonctionnel. 
    - `'docker_webscraping_(date).log'` : pour visualiser l'extraction des donn√©es Ecobalyse, par les services
    - `'docker_testmongodb_(date).log'` : pour visualiser l'acc√®s √† MongoDB (et requ√™tes initiales) par les services
    - `'docker_testredis_(date).log'` : pour visualiser l'acc√®s √† Redis (et requ√™tes initiales) par les services

#### üí¨ Facultatif 

- au besoin, lancer le script `./setup.sh -json` pour supprimer les fichiers *.log*, **les fichiers *.json*,** et (re)lancer les diff√©rents conteneurs du projet


### <a name="tdm-03-04" />[(Re)Charger (`./load.sh`)](#tdm-03)

> **R√©sum√© du(des) script(s) utile(s)**
>
> - `./load.sh` # acc√®de via un *navigateur Web* au Framework **Dash** 
> - `./load.sh -adm` # acc√®de via un *navigateur Web* au Framework **Flask** 

#### Lancer Dash

- lancer le script `./load.sh` pour lancer `Dash` via un *navigateur Web*. <br />

- via [VS Code](https://code.visualstudio.com/), consulter le contenu du fichier .log, pour v√©rifier que l'application `Dash` est active. <br />
    - `'docker_testdash_(date).log'` 

<br />

La page d'accueil `Dash` s'affiche avec les informations suivantes :

...

##### üí¨ Nota 

Lorsque le Framework Web `Dash` est d√©marr√©, via le conteneur *ecbldash*, on peut y acc√©der depuis un navigateur Web : <br />

- soit par l'adresse locale : 127.0.0.1:8050/
- soit par l'adresse IP / SSH publique de la VM, par exemple : 3.252.141.140:8050/

#### Lancer Flask

- lancer le script `./load.sh -adm` pour lancer `Flask` via un *navigateur Web*. <br />

- via [VS Code](https://code.visualstudio.com/), consulter le contenu du fichier .log, pour v√©rifier que l'application `Dash` est active. <br />
    - `'docker_testflask_(date).log'` 

<br />

La page d'accueil `Flask` s'affiche avec les informations suivantes :

```html
Accueil
Bienvenue sur la page d'accueil de votre application Flask !

Pour v√©rifier le bon fonctionnement de votre application, saisir les adresses :

127.0.0.1:5000/testflask, afin de lister les BDD MongoDB
127.0.0.1:5000/testmongo, afin de v√©rifier le contenu Ecobalyse de la BDD MongoDB
127.0.0.1:5000/testredis, afin de v√©rifier le contenu Ecobalyse de la BDD Redis
```

##### üí¨ Nota 

Lorsque le Framework Web `Flask` est d√©marr√©, via le conteneur *ecblflask*, on peut y acc√©der depuis un navigateur Web : <br />

- soit par l'adresse locale : 127.0.0.1:5050/
- soit par l'adresse IP / SSH publique de la VM, par exemple : 3.252.141.140:5050/

## <a name="tdm-05" />[Solution technique](#debut)

### <a name="tdm-05-01" />[Sch√©ma de principe](#tdm-05)

<img src="img/PRJ-ECOBALYSE-00-IMG3.png" alt="Sch√©ma de principe" style="width:750px;height:auto;">

La solution propos√©e se compose de : 

* Un `ETL` qui a la charge de r√©cup√©rer les contenus d'Ecobalyse.

* Une base de donn√©es `MongoDB` o√π sont entrepros√©es les donn√©es r√©cup√©r√©es.
  
* Une base de donn√©es `Redis` utilis√©e comme m√©moire cache, afin d'acc√©l√©rer les requ√™tes.

* Un dashboard `Dash`.

* Un Framework Web `Flask` qui sert d‚Äôinterm√©diaire (API) entre le dashboard `Dash`, les bases de donn√©es `MongoDB` / `Redis`, et un mod√®le `scikit-learn` entra√Æn√© pour des pr√©dictions de <b>Machine Learning</b>.

* Un DAG `Airflow` pour g√©rer l'orchestration de l'ETL.

### <a name="tdm-05-02" />[Dossiers & R√©pertoires](#tdm-05)

```bash
prj_ECOBALYSE
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îú‚îÄ‚îÄ mongo
‚îÇ   ‚îú‚îÄ‚îÄ redis
‚îÇ   ‚îú‚îÄ‚îÄ params01_T-shirt.txt
‚îÇ   ‚îú‚îÄ‚îÄ params02_Pull.txt
‚îÇ   ‚îú‚îÄ‚îÄ params03_Pantalon.txt
‚îÇ   ‚îú‚îÄ‚îÄ params04_Manteau.txt
‚îÇ   ‚îú‚îÄ‚îÄ params05_Maillot-de-bain.txt
‚îÇ   ‚îú‚îÄ‚îÄ params06_Jupe.txt
‚îÇ   ‚îú‚îÄ‚îÄ params07_Jean.txt
‚îÇ   ‚îú‚îÄ‚îÄ params08_Chemise.txt
‚îÇ   ‚îú‚îÄ‚îÄ params09_Chaussettes.txt
‚îÇ   ‚îú‚îÄ‚îÄ params10_Calecon.txt
‚îÇ   ‚îî‚îÄ‚îÄ params11_Slip.txt
‚îú‚îÄ‚îÄ dag
‚îú‚îÄ‚îÄ dash
‚îú‚îÄ‚îÄ etl
‚îú‚îÄ‚îÄ flask
‚îú‚îÄ‚îÄ img
‚îú‚îÄ‚îÄ logs
‚îú‚îÄ‚îÄ mongo
‚îú‚îÄ‚îÄ notebooks
‚îú‚îÄ‚îÄ redis
‚îú‚îÄ‚îÄ PRJ-ECOBALYSE-00-FICHE_PROJET.pdf
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ CONVENTIONS.md
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ lisezMoi.txt
‚îú‚îÄ‚îÄ info.sh
‚îú‚îÄ‚îÄ load.sh
‚îú‚îÄ‚îÄ setup.sh
‚îú‚îÄ‚îÄ init.sh
‚îî‚îÄ‚îÄ starter.sh
```

## <a name="tdm-07" />[D√©tails techniques](#debut)

### <a name="tdm-07-07" />[Architecture](#tdm-07)

#### docker-compose.yml
```bash
version: '3.8'

services:
  ecblwebscraping:
    build:
      context: . # contexte de construction √† la racine du projet
      dockerfile: etl/Dockerfile.etl # chemin relatif vers le Dockerfile
    environment:
      - SERVICE_NAME=ecblwebscraping # variable d‚Äôenvironnement pour le service
    container_name: ecblwebscraping
    volumes:
      - ./logs:/app/logs # r√©pertoire logs de l‚Äôh√¥te dans le conteneur
      - ./data:/app/data # r√©pertoire data de l‚Äôh√¥te dans le conteneur
    networks:
      - my_ecobalyse_network # r√©seau d√©di√© pour le service

  ecblredis:
    build:
      context: . # contexte de construction √† la racine du projet
      dockerfile: redis/Dockerfile.redis # chemin relatif vers le Dockerfile pour Redis
    environment:
      - SERVICE_NAME=ecblredis # variable d‚Äôenvironnement pour le service
    container_name: ecblredis
    ports:
      - "6379:6379"
    volumes:
      - ./logs:/app/logs # r√©pertoire logs de l‚Äôh√¥te dans le conteneur
      - ./data:/app/data # r√©pertoire data de l‚Äôh√¥te dans le conteneur
    networks:
      - my_ecobalyse_network

  ecblmongodb:
    build:
      context: . # contexte de construction √† la racine du projet
      dockerfile: mongo/Dockerfile.mongo # chemin relatif vers le Dockerfile pour MongoDB
    environment:
      - SERVICE_NAME=ecblmongodb # variable d‚Äôenvironnement pour le service
    container_name: ecblmongodb
    ports:
      - "27017:27017"
    volumes:
      - ./data/mongo:/data/db # r√©pertoire data/mongo de l‚Äôh√¥te dans le conteneur
      - ./logs:/app/logs # r√©pertoire logs de l‚Äôh√¥te dans le conteneur
      - ./data:/app/data # r√©pertoire data de l‚Äôh√¥te dans le conteneur
    networks:
      - my_ecobalyse_network
  
  ecblflask:
    build:
      context: . # contexte de construction √† la racine du projet
      dockerfile: flask/Dockerfile.flask # chemin relatif vers le Dockerfile pour Flask
    environment:
      - SERVICE_NAME=ecblflask # variable d‚Äôenvironnement pour le service
      - MONGO_URI=mongodb://ecblmongodb:27017
      - REDIS_URI=redis://ecblredis:6379
    container_name: ecblflask
    ports:
      - "5000:5000"
    depends_on:
      - ecblmongodb
      - ecblredis
    volumes:
      - ./logs:/app/logs # r√©pertoire logs de l‚Äôh√¥te dans le conteneur
    networks:
      - my_ecobalyse_network

networks:
  my_ecobalyse_network:
    name: my_ecobalyse_network

volumes:
  logs:
  data:
```

### <a name="tdm-07-01" />[ETL](#tdm-07)

#### Dossiers & R√©pertoires

```bash
.
‚îú‚îÄ‚îÄ etl
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.etl
‚îÇ   ‚îú‚îÄ‚îÄ constants.py
‚îÇ   ‚îú‚îÄ‚îÄ extract1.py
‚îÇ   ‚îú‚îÄ‚îÄ get_constants.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ utils01.py
‚îÇ   ‚îú‚îÄ‚îÄ utils02.py
‚îÇ   ‚îî‚îÄ‚îÄ utils03.py
.
```

#### Logs du conteneur

conteneur : ecblwebscraping
```bash
Affichage des logs du conteneur : ecblwebscraping...
Attaching to ecblwebscraping
ecblwebscraping    | --------------------------------------------------------------
ecblwebscraping    | ETAPE 01 : R√©cup√©ration des Donn√©es via l'API Ecobalyse v2.4.0
ecblwebscraping    | --------------------------------------------------------------
ecblwebscraping    | VM utilis√©e, √† l'adresse IP / SSH publique : 18.201.106.14
ecblwebscraping    | DataFrame, fichiers 'log' et 'json' cr√©√©s avec succ√®s, par le conteneur.
ecblwebscraping    | 
ecblwebscraping    |
```

#### Dockerfile

fichier : Dockerfile.etl
```bash
# Utiliser l'image Selenium avec Chrome
FROM selenium/standalone-chrome:latest

# Installer Python, pip, Xvfb et les d√©pendances n√©cessaires
USER root
RUN apt-get update && apt-get install -y software-properties-common
RUN add-apt-repository ppa:deadsnakes/ppa
RUN apt-get update && apt-get install -y python3.8 python3.8-venv python3.8-dev build-essential xvfb

# D√©finir le r√©pertoire de travail
WORKDIR /app

# Copier les fichiers n√©cessaires dans l'image Docker
COPY etl/ /app/
COPY starter.sh /app/

# Cr√©er un environnement virtuel Python avec Python 3.8
RUN python3.8 -m venv venv

# Activer l'environnement virtuel et installer les d√©pendances Python
RUN /bin/bash -c "source venv/bin/activate && pip install --no-cache-dir -r /app/requirements.txt"

# D√©clarer les volumes pour les r√©pertoires logs et data
VOLUME ["/app/logs", "/app/data"]

# D√©finir la commande par d√©faut pour ex√©cuter le script
CMD ["bash", "starter.sh"]
```

### <a name="tdm-07-02" />[MongoDB](#tdm-07)

#### Dossiers & R√©pertoires

```bash
.
‚îú‚îÄ‚îÄ mongo
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.mongo
‚îÇ   ‚îú‚îÄ‚îÄ constants1.py
‚îÇ   ‚îú‚îÄ‚îÄ get_constants1.py
‚îÇ   ‚îú‚îÄ‚îÄ init_mongo.js
‚îÇ   ‚îú‚îÄ‚îÄ init_mongo.sh
‚îÇ   ‚îú‚îÄ‚îÄ mongo.conf
‚îÇ   ‚îî‚îÄ‚îÄ test_mongo.py
.
```

#### Logs du conteneur

conteneur : ecblmongodb
```bash
Affichage des logs du conteneur : ecblmongodb...
Attaching to ecblmongodb
ecblmongodb        | ------------------------------------------------------------
ecblmongodb        | ETAPE 02 : Stockage des Donn√©es Ecobalyse v2.4.0 via MongoDB
ecblmongodb        | ------------------------------------------------------------
ecblmongodb        | VM utilis√©e, √† l'adresse IP / SSH publique : 18.201.106.14
ecblmongodb        | 
ecblmongodb        | about to fork child process, waiting until server is ready for connections.
ecblmongodb        | forked process: 15
ecblmongodb        | child process started successfully, parent exiting
ecblmongodb        | MongoDB shell version v5.0.30
ecblmongodb        | connecting to: mongodb://127.0.0.1:27017/?compressors=disabled&gssapiServiceName=mongodb
ecblmongodb        | Implicit session: session { "id" : UUID("42c41132-a00e-49d8-8fa8-db77bd20c579") }
ecblmongodb        | MongoDB server version: 5.0.30
ecblmongodb        | ================
ecblmongodb        | Warning: the "mongo" shell has been superseded by "mongosh",
ecblmongodb        | which delivers improved usability and compatibility.The "mongo" shell has been deprecated and will be removed in
ecblmongodb        | an upcoming release.
ecblmongodb        | For installation instructions, see
ecblmongodb        | https://docs.mongodb.com/mongodb-shell/install/
ecblmongodb        | ================
ecblmongodb        | switched to db admin
ecblmongodb        | bye
ecblmongodb        | MongoDB shell version v5.0.30
ecblmongodb        | connecting to: mongodb://127.0.0.1:27017/?compressors=disabled&gssapiServiceName=mongodb
ecblmongodb        | Implicit session: session { "id" : UUID("e09b9ab9-9e34-46b3-9a77-0c3220c68cc7") }
ecblmongodb        | MongoDB server version: 5.0.30
ecblmongodb        | 
ecblmongodb        | Base De Donn√©es MongoDB et fichier 'log' cr√©√©s avec succ√®s, par le conteneur.
ecblmongodb        | 
```

#### Dockerfile

fichier : Dockerfile.mongo
```bash
# Utilise l'image officielle de MongoDB comme image de base
FROM mongo:5.0

# D√©finir les variables d'environnement n√©cessaires
ENV MONGO_INITDB_ROOT_USERNAME=admin
ENV MONGO_INITDB_ROOT_PASSWORD=admin

# Installer Python, pip et le client MongoDB
RUN apt-get update && apt-get install -y python3 python3-pip python3-venv wget gnupg curl

# Ajouter la cl√© GPG de MongoDB
RUN wget -qO - https://www.mongodb.org/static/pgp/server-5.0.asc | apt-key add -

# Ajouter le d√©p√¥t MongoDB pour la version 5.0
RUN echo "deb [ arch=amd64 ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/5.0 multiverse" | tee /etc/apt/sources.list.d/mongodb-org-5.0.list

# Mettre √† jour les sources et installer le client MongoDB
RUN apt-get update && apt-get install -y mongodb-org-shell

# Cr√©er un environnement virtuel
RUN python3 -m venv /opt/venv

# Activer l'environnement virtuel et installer pymongo et jsonschema
RUN /opt/venv/bin/pip install --upgrade pip
RUN /opt/venv/bin/pip install pymongo
RUN /opt/venv/bin/pip install jsonschema  # Ajout de l'installation de jsonschema

# Copier les scripts d'initialisation et de test dans le conteneur
COPY mongo/init_mongo.js /docker-entrypoint-initdb.d/
COPY mongo/test_mongo.py /app/test_mongo.py
COPY mongo/init_mongo.sh /usr/local/bin/init_mongo.sh
COPY mongo/mongo.conf /etc/mongod.conf
RUN chmod +x /usr/local/bin/init_mongo.sh

# Cr√©er le r√©pertoire de logs
RUN mkdir -p /app/logs

# Copier les fichiers n√©cessaires dans l'image Docker
COPY mongo/constants1.py /app/
COPY mongo/get_constants1.py /app/

# Ajouter /app au PYTHONPATH
ENV PYTHONPATH="/app"

# Exposer le port MongoDB
EXPOSE 27017

# D√©finir le point d'entr√©e pour ex√©cuter le script d'initialisation
ENTRYPOINT ["/usr/local/bin/init_mongo.sh"]
```

### <a name="tdm-07-03" />[Redis](#tdm-07)

#### Dossiers & R√©pertoires

```bash
.
‚îú‚îÄ‚îÄ redis
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.redis
‚îÇ   ‚îú‚îÄ‚îÄ constants2.py
‚îÇ   ‚îú‚îÄ‚îÄ get_constants2.py
‚îÇ   ‚îú‚îÄ‚îÄ init_redis.sh
‚îÇ   ‚îú‚îÄ‚îÄ redis.conf
‚îÇ   ‚îî‚îÄ‚îÄ test_redis.py
.
```

#### Logs du conteneur

conteneur : ecblredis
```bash
Affichage des logs du conteneur : ecblredis...
Attaching to ecblredis
ecblredis          | ----------------------------------------------------------
ecblredis          | ETAPE 02 : Stockage des Donn√©es Ecobalyse v2.4.0 via Redis
ecblredis          | ----------------------------------------------------------
ecblredis          | VM utilis√©e, √† l'adresse IP / SSH publique : 18.201.106.14
ecblredis          | 
ecblredis          | 13:C 30 Oct 2024 15:45:48.651 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
ecblredis          | 13:C 30 Oct 2024 15:45:48.651 * Redis version=7.4.1, bits=64, commit=00000000, modified=0, pid=13, just started
ecblredis          | 13:C 30 Oct 2024 15:45:48.651 * Configuration loaded
ecblredis          | 13:M 30 Oct 2024 15:45:48.652 * monotonic clock: POSIX clock_gettime
ecblredis          | 13:M 30 Oct 2024 15:45:48.653 * Running mode=standalone, port=6379.
ecblredis          | 13:M 30 Oct 2024 15:45:48.654 * Server initialized
ecblredis          | 13:M 30 Oct 2024 15:45:48.654 * Ready to accept connections tcp
ecblredis          | 
ecblredis          | Test Redis de r√©cup√©ration JSON : 
ecblredis          | Attendre que le fichier JSON soit cr√©√©...
ecblredis          | 
ecblredis          | 
ecblredis          | Base De Donn√©es Redis et fichier 'log' cr√©√©s avec succ√®s, par le conteneur.
ecblredis          |
```

#### Dockerfile

fichier : Dockerfile.redis
```bash
# Utiliser l'image officielle de Redis comme image de base
FROM redis:latest

# Installer procps pour obtenir sysctl et Python avec pip
RUN apt-get update && apt-get install -y procps python3 python3-pip python3-venv curl

# Cr√©er un environnement virtuel
RUN python3 -m venv /opt/venv

# Activer l'environnement virtuel et installer les packages n√©cessaires
RUN /opt/venv/bin/pip install --upgrade pip
RUN /opt/venv/bin/pip install redis[hiredis]
RUN /opt/venv/bin/pip install cerberus

# Cr√©er le r√©pertoire logs
RUN mkdir -p /app/logs

# Copier les fichiers n√©cessaires dans l'image Docker
COPY redis/constants2.py /app/
COPY redis/get_constants2.py /app/

# Copier les fichiers de configuration et le script d'initialisation
COPY redis/redis.conf /usr/local/etc/redis/redis.conf
COPY redis/init_redis.sh /usr/local/bin/init_redis.sh
RUN chmod +x /usr/local/bin/init_redis.sh

# Copier le fichier test.py dans le conteneur
COPY redis/test_redis.py /app/test_redis.py

# D√©finir le point d'entr√©e pour ex√©cuter le test
ENTRYPOINT ["/usr/local/bin/init_redis.sh"]
CMD ["/opt/venv/bin/python", "/app/test_redis.py"]

```

### <a name="tdm-07-04" />[Flask](#tdm-07)

#### Dossiers & R√©pertoires

```bash
.
‚îú‚îÄ‚îÄ flask
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.flask
‚îÇ   ‚îú‚îÄ‚îÄ constants3.py
‚îÇ   ‚îú‚îÄ‚îÄ get_constants3.py
‚îÇ   ‚îú‚îÄ‚îÄ init_flask.sh
‚îÇ   ‚îú‚îÄ‚îÄ mongo_queries.py
‚îÇ   ‚îú‚îÄ‚îÄ redis_queries.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ stylesheets
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ listMongoBDD.css
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ styles.css
‚îÇ   ‚îú‚îÄ‚îÄ templates
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bienvenue.html
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ listMongoBDD.html
‚îÇ   ‚îú‚îÄ‚îÄ test_flask.py
‚îÇ   ‚îî‚îÄ‚îÄ utils.py
.
```

#### Logs du conteneur

conteneur : ecblflask
```bash
Attaching to ecblflask
ecblflask          | --------------------------------------------------------------
ecblflask          | ETAPE 03 : Consommation des Donn√©es Ecobalyse v2.4.0 via Flask
ecblflask          | --------------------------------------------------------------
ecblflask          | VM utilis√©e, √† l'adresse IP / SSH publique : 3.252.141.140
ecblflask          | 
ecblflask          | Framework Web Flask d√©marr√©. Accessible depuis les adresses : 127.0.0.1:5000/ , ou : 3.252.141.140:5000/
ecblflask          | Fichier 'log' cr√©√© avec succ√®s, par le conteneur.
ecblflask          | 
ecblflask          | [2024-10-30 18:35:07,105] INFO in test_flask: Application Flask active.
ecblflask          |  * Serving Flask app 'test_flask.py'
ecblflask          |  * Debug mode: off
ecblflask          | WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
ecblflask          |  * Running on all addresses (0.0.0.0)
ecblflask          |  * Running on http://127.0.0.1:5000
ecblflask          |  * Running on http://172.22.0.5:5000
ecblflask          | Press CTRL+C to quit
```

#### Dockerfile

fichier : Dockerfile.flask
```bash
# Utiliser l'image Python slim
FROM python:3.9-slim

# D√©finir le r√©pertoire de travail
WORKDIR /app

# Installer curl et autres d√©pendances syst√®me
RUN apt-get update && apt-get install -y curl

# Copier le fichier requirements.txt dans l'image Docker
COPY flask/requirements.txt /app/requirements.txt

# Installer les d√©pendances Python
RUN pip install --no-cache-dir -r /app/requirements.txt 

# Copier tous les fichiers du r√©pertoire flask dans l'image Docker
COPY flask/ /app/

RUN mkdir -p logs

# Rendre le script init_flask.sh ex√©cutable
RUN chmod +x /app/init_flask.sh

# D√©finir la commande par d√©faut pour ex√©cuter le script init_flask.sh
CMD ["/app/init_flask.sh"]
```

### <a name="tdm-07-05" />[Dash](#tdm-07)

#### Dossiers & R√©pertoires

```bash
.
Dash ...
.
```

### <a name="tdm-07-06" />[AirFlow](#tdm-07)

#### Dossiers & R√©pertoires

```bash
.
AirFlow ...
.
```

## <a name="tdm-06" />[A propos d'Ecobalyse](#debut)
__√âcobalyse__ est un outil d√©velopp√© par l'√âtat fran√ßais pour calculer l'impact √©cologique des produits textiles et alimentaires distribu√©s en France. Il vise √† fournir des informations sur l'empreinte environnementale de ces produits, permettant ainsi aux consommateurs de prendre des d√©cisions plus √©clair√©es  et durables sur leurs choix de consommation. 
    
En lien avec les pr√©occupations actuelles (l'industrie textile est l'une des plus polluantes au monde), __√âcobalyse__ vise √† acc√©l√©rer la mise en place de l'affichage environnemental, pour favoriser un mod√®le de production plus durable.
    
__Voici quelques points cl√©s √† propos d'√âcobalyse__ :
    
- `Objectif` : __√âcobalyse__ permet de comprendre et de calculer les impacts √©cologiques des produits distribu√©s en France.

- `√âco-score` : __√âcobalyse__ propose un √©co-score pour informer les consommateurs sur l'impact environnemental des produits qu'ils ach√®tent.    
    
- `Collaboration ouverte` : __√âcobalyse__ est un mode de collaboration ouvert √† la critique et aux suggestions, dans le but d'aider √† √©laborer la future m√©thode r√©glementaire fran√ßaise.

- [`API ouverte`](https://api.gouv.fr/les-api/api-ecobalyse) : __√âcobalyse__ propose une __interface de programmation applicative__ (__API__) pour connecter le calculateur √âcobalyse √† d'autres services num√©riques. L'[__API__](https://api.gouv.fr/les-api/api-ecobalyse) est test√©e dans le cadre de l'exp√©rimentation Xtex, conform√©ment √† la loi Climat et R√©silience.
    
    Ci-apr√®s quelques exemples d'utilisation de l'[__API__](https://api.gouv.fr/les-api/api-ecobalyse) __√âcobalyse__ pour estimer les impacts environnementaux des produits textiles : 
    
        1. Interroger la base de donn√©es des indicateurs d'impacts environnementaux des produits textiles. 
        R√©cup√©rer des informations sur les impacts environnementaux d'un v√™tement en fonction de crit√®res tels que 
        la tra√ßabilit√©, la mati√®re et le recyclage.
    
        2. Calculer les impacts pour chaque produit.
        Estimer, pour chaque produit textile : l'impact carbone, l'impact sur la couche d'ozone, l'impact sur la 
        qualit√© de l'eau, le co√ªt √©nerg√©tique, l'impact sur l'eutrophisation de l'eau et des terres, l'impact sur 
        l'acidification terrestre des eaux douces, l'utilisation du sol, l'utilisation de min√©raux. 

        3. Tester le simulateur.
        Explorer les impacts environnementaux de diff√©rents produits textiles.
    
Toutes marques, producteurs, ou distributeurs peutvent contribuer √† am√©liorer le calcul d'impacts √©cologiques, en partageant leurs donn√©es et en participant aux travaux collectifs.
    
Pour en savoir plus, on peut visiter le site d'__√âcobalyse__ [ici](https://ecobalyse.beta.gouv.fr/). 

__A voir √©galement :__

- [GitBook `√âcobalyse`](https://fabrique-numerique.gitbook.io/ecobalyse)
- [Explorateur `√âcobalyse`](https://ecobalyse.beta.gouv.fr/#/explore/textile/processes)    
- [Documentation de `API` √âcobalyse](https://api.gouv.fr/documentation/api-ecobalyse)
- [Ademe](https://affichage-environnemental.ademe.fr/)

<img src="img/PRJ-ECOBALYSE-00-IMG1.jpg" alt="A propos" style="width:750px;height:auto;">

[(Retour au d√©but)](#debut)
