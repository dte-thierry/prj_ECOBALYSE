{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59b37832-086d-4c98-b2b3-fb54cf706cd0",
   "metadata": {},
   "source": [
    "<a name=\"anchorUp\" />\n",
    "\n",
    "<img src=\"PRJ-ECOBALYSE-00-LOGO.png\" alt=\"Logo DataScientest\" style=\"width:250px;height:auto;\">\n",
    "\n",
    "# FORMATION : DataScientest / Data Engineer\n",
    "# PROJET : Impact Textile avec EcoBalyse\n",
    "# ETAPE 01 - Récolte des données - Sélénium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a30bc5-6930-4011-a634-894172225e23",
   "metadata": {},
   "source": [
    "## Temps Partiel (9 mois) - jan24_continu_de / cde_projet_ecobalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28c223c-ecc1-4823-b3f9-2aeab803828a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dernière Mise A Jour du Document : Mer. 23/10/2024 - Version : 0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffbdea2-d92d-404a-90dd-6a5b91e6d7db",
   "metadata": {},
   "source": [
    "<div style=\"padding-right: 200px;\">\n",
    "\n",
    "---\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b423a90c-e861-4ac5-ac94-cf7a5d583b6e",
   "metadata": {},
   "source": [
    "<a name=\"summaryUp\" />\n",
    "\n",
    "## Sommaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dd3da1-9deb-4ef8-bb4e-f6d28d34f8f1",
   "metadata": {},
   "source": [
    "<div style=\"padding-right: 200px;\">\n",
    "\n",
    "[**Schéma De Principe**](#tdm-01)  \n",
    "[**Etape en cours**](#mongodb-02)  \n",
    "[**GitHub**](#mongodb-03)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c92974-c889-450b-b94f-7f97d445ade9",
   "metadata": {},
   "source": [
    "<div style=\"padding-right: 200px;\">\n",
    "\n",
    "[`Web Scraping`](#tbm-04) \n",
    "\n",
    "[*Fonction(s) utiles(s)*](#tbm-04-01)\n",
    "- [*get_explorer_url()*](#tbm-04-01-01)  \n",
    "- [*diviser_nom()*](#tbm-04-01-02)\n",
    "- [*extraire_masse()*](#tbm-04-01-03)\n",
    "- [*extraire_matiere()*](#tbm-04-01-04)\n",
    "- [*get_ecobalyse_datas()*](#tbm-04-01-05) \n",
    "\n",
    "[**Récolter les données de l'Explorateur Ecobalyse**](#tbm-04-02) \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69b89dd-8120-4ccd-91ad-eb3378890950",
   "metadata": {},
   "source": [
    "|                                |                                 |\n",
    "|:--:                            |:--:                             |\n",
    "| [(Aller au début)](#anchorUp)  | [(Aller à la fin)](#anchorDown) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a6cac2-cdeb-4399-b030-20979652c105",
   "metadata": {},
   "source": [
    "### <a name=\"tdm-01\" />Schéma De Principe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4518f7f2-19df-47ad-ab15-9760156bdf00",
   "metadata": {},
   "source": [
    "<div style=\"padding-right: 200px;\">\n",
    "\n",
    "<b>Data Pipeline :</b>  \n",
    "<img src=\"PRJ-ECOBALYSE-01-WEB_SCRAPING1_img01.png\" alt=\"Schéma De Principe\" style=\"width:900px;height:auto;\">\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4239a00e-db04-41f3-afce-082938dba2a0",
   "metadata": {},
   "source": [
    "<div style=\"padding-right: 200px;\">\n",
    "\n",
    "Visitez le site d'__Écobalyse__, [ici](https://ecobalyse.beta.gouv.fr/)<sup>1 , 2 , 3 , 4 , 5 , 6 , 7 , 8</sup>.\n",
    "\n",
    "<i>En savoir plus</i> : <sup>1</sup>[Simulateur](https://ecobalyse.beta.gouv.fr/#/textile/simulator) , <sup>2</sup>[Explorateur](https://ecobalyse.beta.gouv.fr/#/explore/textile) , <sup>3</sup>[API](https://ecobalyse.beta.gouv.fr/#/api) , <sup>4</sup>[Documentation](https://fabrique-numerique.gitbook.io/ecobalyse) , <sup>5</sup>[GitHub](https://github.com/MTES-MCT/ecobalyse) , <sup>6</sup>[fashiongreenhub.org](https://www.fashiongreenhub.org/2023/08/31/lecobalyse-un-outil-pour-accelerer-la-mise-en-place-de-laffichage-environnemental/) , <sup>7</sup>[gorfou.fr](https://www.gorfou.fr/ecobalyse-calcule-vos-impacts-environnementaux/) , <sup>8</sup>[mtes-mct.github.io](https://mtes-mct.github.io/portail/startup/ecobalyse/)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54708f2-5ce8-4d7e-a755-3fbf8bfac2fd",
   "metadata": {},
   "source": [
    "|                                    | \n",
    "|:--:                                |\n",
    "| [(Retour au sommaire)](#summaryUp) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10c6db4-f0dc-4042-9e91-9cde7ce32f06",
   "metadata": {},
   "source": [
    "### <a name=\"mongodb-02\" />Etape en cours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4149e2-7e14-4ea9-8e6f-6075228132f4",
   "metadata": {},
   "source": [
    "<div style=\"padding-right: 200px;\">\n",
    "\n",
    "<b>- Etape :</b> 01  \n",
    "    \n",
    "<b>- Description :</b> Récolte des données  \n",
    "    \n",
    "<b>- Objectif :</b>  \n",
    "1. L'objectif de cette étape est d'extraire les données nécessaires à partir de l'`API d'Ecobalyse`. Vous devrez écrire des scripts pour interroger l'_API_ et récupérer les informations pertinentes sur les impacts environnementaux des produits textiles.    \n",
    "\n",
    "2. Si nécessaire, vous pouvez également utiliser des techniques de `web scraping` pour compléter les données de l'API comme par exemple des données sur les habitudes de consommations textiles des français.\n",
    "    \n",
    "<b>- Modules / MasterClass / templates :</b>  \n",
    "133 - Web Scraping avec `Beautiful Soup` (ou `Sélénium`)\n",
    "    \n",
    "<b>Conditions de validation du projet :</b>  \n",
    "Fichier explicatif du traitement (doc / pdf). Un fichier `json` d’exemple de récupération.   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ccb415-a216-406b-896e-52522ff83398",
   "metadata": {},
   "source": [
    "|                                    | \n",
    "|:--:                                |\n",
    "| [(Retour au sommaire)](#summaryUp) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794b87ba-635e-4c5e-b8ca-0b08f0c235dc",
   "metadata": {},
   "source": [
    "### <a name=\"mongodb-03\" />GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d9559-b298-4046-acb8-14fff62a2604",
   "metadata": {},
   "source": [
    "<div style=\"padding-right: 200px;\">  \n",
    "\n",
    "Voir : https://github.com/dte-thierry/prj_ECOBALYSE\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd50836-6f5f-4852-aa50-ec3a81caeede",
   "metadata": {},
   "source": [
    "|                                    | \n",
    "|:--:                                |\n",
    "| [(Retour au sommaire)](#summaryUp) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace6bea-9452-4e3b-ae93-268e65adec79",
   "metadata": {},
   "source": [
    "### <a name=\"tbm-04\" />Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2719303a-2ea7-4156-ad20-e8f34fb34c28",
   "metadata": {},
   "source": [
    "#### <a name=\"tbm-04-01\" />Fonction(s) utile(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2074fa6c-f255-48d5-b94a-3814c819beaf",
   "metadata": {},
   "source": [
    "##### <a name=\"tbm-04-01-01\" />get_explorer_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b98be2-fff5-401a-ad2e-7a0198044380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explorer_url(url, columns):\n",
    "    \"\"\"\n",
    "    Récupère les données d'une table HTML à partir d'une URL donnée et les retourne sous forme de DataFrame.\n",
    "\n",
    "    Paramètres:\n",
    "    -----------\n",
    "    url : str\n",
    "        L'URL de la page web contenant la table HTML à scraper.\n",
    "    columns : list\n",
    "        Une liste de chaînes de caractères représentant les noms des colonnes pour le DataFrame retourné.\n",
    "\n",
    "    Retourne:\n",
    "    ---------\n",
    "    pandas.DataFrame\n",
    "        Un DataFrame contenant les données de la table HTML avec les colonnes spécifiées.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - La fonction utilise Selenium pour automatiser le navigateur Chrome.\n",
    "    - Les options du navigateur sont configurées pour désactiver les infobars, extensions et notifications.\n",
    "    - Le navigateur est exécuté en mode sans tête pour éviter l'ouverture d'une fenêtre graphique.\n",
    "    - Les capacités SSL sont acceptées pour gérer les certificats sécurisés et non sécurisés.\n",
    "    - La fonction attend jusqu'à 10 secondes pour que la page se charge complètement avant de scraper les données.\n",
    "    - Le DataFrame retourné aura les colonnes nommées selon la liste fournie en paramètre.\n",
    "    \"\"\"\n",
    "    # Charger les librairies nécessaires\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "    from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "    \n",
    "    # Définir les capacités\n",
    "    capabilities = DesiredCapabilities.CHROME.copy()\n",
    "    capabilities['acceptSslCerts'] = True \n",
    "    capabilities['acceptInsecureCerts'] = True\n",
    "\n",
    "    # Ajouter les capacités aux options\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-infobars\")  # Désactiver les fenêtres contextuelles\n",
    "    options.add_argument(\"--disable-extensions\")  # Désactiver les extensions\n",
    "    options.add_argument(\"--disable-notifications\")  # Désactiver les notifications\n",
    "    options.add_experimental_option('prefs', {'profile.default_content_setting_values.notifications': 2}) # Désactiver les notifications\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--headless\")  # Exécuter en mode sans tête\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--window-size=1920,1080')\n",
    "\n",
    "    # Ajouter les capacités aux options\n",
    "    options.add_experimental_option('prefs', capabilities)\n",
    "    \n",
    "    # --- A ajouter pour la VMb Ubuntu Server 20.04 LTS\t16Go RAM 25Go DD ---\n",
    "    # --- https://learn.datascientest.com/lesson/349/3682 (AirFlow)      ---\n",
    "    #\n",
    "    # Vérifier si le script est exécuté dans un conteneur Docker\n",
    "    # if os.path.exists('/.dockerenv'):\n",
    "    #     # Spécifier le chemin de l'exécutable ChromeDriver / conteneur\n",
    "    #     chrome_service = Service('/usr/bin/chromedriver')\n",
    "    # else:\n",
    "    #     # Spécifier le chemin de l'exécutable ChromeDriver / manuel\n",
    "    #     chrome_service = Service('/usr/bin/chromedriver')\n",
    "\n",
    "    # Créer une nouvelle instance de navigateur avec des options\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    # --- A ajouter pour la VMb Ubuntu Server 20.04 LTS\t16Go RAM 25Go DD ---\n",
    "    # --- https://learn.datascientest.com/lesson/349/3682 (AirFlow)      ---\n",
    "    #\n",
    "    # Créer une nouvelle instance de navigateur avec des options et le service\n",
    "    # driver = webdriver.Chrome(service=chrome_service, options=options)\n",
    "    \n",
    "    # Rechercher la page à afficher \n",
    "    driver.get(url)\n",
    "    \n",
    "    # Attendre que la page se charge\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    \n",
    "    # Extraire les données find_elements(By.CSS_SELECTOR, 'table tr')\n",
    "    # Sélecteur CSS pour les lignes du tableau\n",
    "    data = []\n",
    "    rows = driver.find_elements(By.CSS_SELECTOR, 'table tr') \n",
    "    \n",
    "    # Sélecteur CSS pour les colonnes du tableau\n",
    "    for row in rows:\n",
    "        cols = row.find_elements(By.CSS_SELECTOR, 'td')  \n",
    "        cols = [col.text for col in cols]\n",
    "        data.append(cols)\n",
    "    \n",
    "    # Fermer le webdriver\n",
    "    driver.close()\n",
    "\n",
    "    # Créer le dataframe\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Nommer les colonnes\n",
    "    df.columns = columns\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57e6197-58ee-4d61-9f96-24257cb95a39",
   "metadata": {},
   "source": [
    "|                                    | \n",
    "|:--:                                |\n",
    "| [(Retour au sommaire)](#summaryUp) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac8afd3-b941-4f16-bcc6-100bac7e05c0",
   "metadata": {},
   "source": [
    "##### <a name=\"tbm-04-01-02\" />diviser_nom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0675ece-ec95-4a76-b421-e0ee3fb302e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diviser_nom(ligne):\n",
    "    \"\"\"\n",
    "    Divise une chaîne de caractères représentant un nom en plusieurs éléments distincts.\n",
    "\n",
    "    Cette fonction prend une chaîne de caractères contenant des informations séparées par des tirets\n",
    "    et les divise en trois parties : le type, le pays et le mode. Elle traite également les cas où\n",
    "    le pays est indiqué comme \"Majorant par défaut\".\n",
    "\n",
    "    Paramètres :\n",
    "    -----------\n",
    "    ligne : str\n",
    "        La chaîne de caractères à diviser. Elle est supposée contenir des informations séparées par des tirets.\n",
    "\n",
    "    Retour :\n",
    "    --------\n",
    "    pandas.Series\n",
    "        Une série contenant trois éléments : le type, le pays et le mode.\n",
    "    \"\"\"\n",
    "    # Charger les librairies nécessaires\n",
    "    import pandas as pd\n",
    "    \n",
    "    elements = ligne.rsplit('-', maxsplit=3)  # Divise la chaîne en partant de la droite\n",
    "    elements = [e.strip() for e in elements]  # Supprime les espaces superflus\n",
    "    # Assignation des éléments aux colonnes en tenant compte de l'ordre inverse\n",
    "    type = elements[0]\n",
    "    mode = elements[-1]\n",
    "    pays = elements[1] if elements[1] != \"Majorant par défaut\" else \"Pays inconnu\"\n",
    "    \n",
    "    return pd.Series([type, pays, mode])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38c026a-2983-4f8a-823b-c3eff3b54912",
   "metadata": {},
   "source": [
    "|                                    | \n",
    "|:--:                                |\n",
    "| [(Retour au sommaire)](#summaryUp) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c7d8d-da77-4f1a-9d87-7fab314c8305",
   "metadata": {},
   "source": [
    "##### <a name=\"tbm-04-01-03\" />extraire_masse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec7ed2b1-be7b-430f-b022-5e42da745b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraire_masse(type):\n",
    "    \"\"\"\n",
    "    Extrait la masse d'une chaîne de caractères et la convertit en kilogrammes.\n",
    "\n",
    "    Cette fonction utilise une expression régulière pour rechercher une masse exprimée en grammes\n",
    "    entre parenthèses dans une chaîne de caractères. Si une masse est trouvée, elle est convertie\n",
    "    en kilogrammes et retournée. Sinon, la fonction retourne None.\n",
    "\n",
    "    Paramètres :\n",
    "    -----------\n",
    "    type : str\n",
    "        La chaîne de caractères contenant potentiellement une masse entre parenthèses, suivie de 'g'.\n",
    "\n",
    "    Retour :\n",
    "    --------\n",
    "    float or None\n",
    "        La masse en kilogrammes si elle est trouvée, sinon None.\n",
    "    \"\"\"\n",
    "    # Charger les librairies utiles\n",
    "    import re\n",
    "    \n",
    "    # Utiliser une expression régulière pour trouver la masse entre parenthèses\n",
    "    mass = re.search(r'\\((.*?)g\\)', type)\n",
    "    # Si une masse est trouvée, la retourner en tant que float\n",
    "    if mass:\n",
    "        return float(mass.group(1))/1000\n",
    "    # Si aucune masse n'est trouvée, retourner None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c042105a-2644-4dcf-bbcc-116eeaea5b2f",
   "metadata": {},
   "source": [
    "|                                    | \n",
    "|:--:                                |\n",
    "| [(Retour au sommaire)](#summaryUp) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e5635-c6dc-47ce-9551-b6e79204adc1",
   "metadata": {},
   "source": [
    "##### <a name=\"tbm-04-01-04\" />extraire_matiere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f16914c-021a-4c7e-9ace-b43ad1eaf828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraire_matiere(type_colonne):\n",
    "    \"\"\"\n",
    "    Extrait la matière d'une chaîne de caractères représentant un type de produit.\n",
    "\n",
    "    Cette fonction utilise une expression régulière pour rechercher des matières spécifiques dans une chaîne de caractères.\n",
    "    Si une matière est trouvée, elle est retournée. Sinon, une chaîne vide est retournée.\n",
    "\n",
    "    Paramètres :\n",
    "    -----------\n",
    "    type_colonne : str\n",
    "        La chaîne de caractères contenant le type de produit.\n",
    "\n",
    "    Retour :\n",
    "    --------\n",
    "    str\n",
    "        La matière trouvée dans la chaîne de caractères, ou une chaîne vide si aucune matière n'est trouvée.\n",
    "    \"\"\"\n",
    "    # Charger les librairies utiles\n",
    "    import re\n",
    "    \n",
    "    # Liste des matières possibles. Attention : faute d'orthographe pour 'paysane' au lieu de 'paysanne' !\n",
    "    matieres = ['laine paysane', 'synthétique', 'coton bio', 'polyester', 'viscose', 'laine', 'coton', 'lin']\n",
    "\n",
    "    # Créer une expression régulière à partir de la liste des matières\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(matiere) for matiere in matieres) + r')\\b'\n",
    "\n",
    "    # Vérifier si 'laine paysane' est dans la chaîne\n",
    "    if 'laine paysane' in type_colonne:\n",
    "        return 'laine paysane'\n",
    "    \n",
    "    # Rechercher les autres matières\n",
    "    match = re.search(pattern, type_colonne)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    \n",
    "    return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b351a70-b6dc-42fc-8063-ec8975b69a02",
   "metadata": {},
   "source": [
    "|                                    | \n",
    "|:--:                                |\n",
    "| [(Retour au sommaire)](#summaryUp) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08ed217-a295-4b82-8da9-4e8c6e48d592",
   "metadata": {},
   "source": [
    "##### <a name=\"tbm-04-01-05\" />get_ecobalyse_datas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5285b16a-a41e-4759-bfe2-b64bd0cdd1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ecobalyse_datas(url, columns, json_output_path):\n",
    "    \"\"\"\n",
    "    Récupère et traite les données de l'Explorateur Ecobalyse, puis les sauvegarde en fichier JSON.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): L'URL de l'Explorateur Ecobalyse.\n",
    "    columns (list): Liste des colonnes à extraire.\n",
    "    json_output_path (str): Chemin du fichier JSON où sauvegarder les données.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Le DataFrame contenant les données traitées.\n",
    "\n",
    "    Description:\n",
    "    Cette fonction utilise Selenium pour extraire les données de l'Explorateur Ecobalyse à partir de l'URL fournie.\n",
    "    Les données sont ensuite traitées pour :\n",
    "    - Trier par catégorie et ECS.\n",
    "    - Réinitialiser les indices.\n",
    "    - Supprimer les espaces en début et fin de chaîne dans la colonne 'Nom'.\n",
    "    - Supprimer les colonnes inutiles.\n",
    "    - Convertir la colonne 'ecs' en type entier.\n",
    "    - Diviser les informations de la colonne 'Nom' en plusieurs colonnes.\n",
    "    - Extraire la masse et la matière des colonnes correspondantes.\n",
    "    - Renommer et réorganiser les colonnes.\n",
    "    Le DataFrame résultant est sauvegardé en fichier JSON et retourné.\n",
    "    \"\"\"\n",
    "    # Charger les librairies utiles\n",
    "    import pandas as pd\n",
    "    import time\n",
    "    import re\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    # Lien vers la documentation\n",
    "    print(\"Les informations relatives à ces exemples de textiles sont disponibles depuis le lien :\\nhttps://fabrique-numerique.gitbook.io/ecobalyse/textile/exemples\\n\")\n",
    "\n",
    "    # Extraire via Selenium les données de l'Explorateur [Exemples] et créer un DataFrame\n",
    "    print(\"Récupérer les données de l'Explorateur Ecobalyse ...\")\n",
    "    df_exemples = get_explorer_url(url, columns)\n",
    "\n",
    "    # Trier le DataFrame par \"Catégorie\" en ordre décroissant\n",
    "    df_exemples = df_exemples.sort_values(by=['Categorie', 'ecs'], ascending=[False, True])\n",
    "\n",
    "    # Réinitialiser les indices du DataFrame\n",
    "    df_exemples = df_exemples.reset_index(drop=True)\n",
    "\n",
    "    # Supprimer les espaces de début et fin de chaîne de caractère de la colonne 'Nom'\n",
    "    df_exemples['Nom'] = df_exemples['Nom'].str.strip()\n",
    "\n",
    "    # Supprimer les colonnes '.' et 'pef'\n",
    "    df_exemples = df_exemples.drop(columns=['.'])\n",
    "    df_exemples = df_exemples.drop(columns=['pef'])\n",
    "\n",
    "    # Convertir la colonne 'ecs' en type : Integer\n",
    "    # regex : remplacer tout caractère non numérique par une chaîne vide\n",
    "    df_exemples['ecs'] = df_exemples['ecs'].str.replace(r'\\D', '', regex=True).astype(int)\n",
    "\n",
    "    # Diviser les informations de la colonne 'Nom'\n",
    "    df_exemples[['Type', 'Pays', 'Mode']] = df_exemples['Nom'].apply(diviser_nom)\n",
    "\n",
    "    # Récupérer la masse depuis la colonne 'Type'\n",
    "    df_exemples['Masse'] = df_exemples['Type'].apply(extraire_masse)\n",
    "\n",
    "    # Supprimer la masse de la colonne 'Type'\n",
    "    df_exemples['Type'] = df_exemples['Type'].apply(lambda x: re.sub(r'\\(.*?g\\)', '', x).strip())\n",
    "\n",
    "    # Récupérer la matière depuis la colonne 'Type'\n",
    "    df_exemples['Matiere'] = df_exemples['Type'].apply(extraire_matiere)\n",
    "\n",
    "    # Supprimer la colonne 'Type'\n",
    "    df_exemples = df_exemples.drop(columns=['Type'])\n",
    "\n",
    "    # Renommer la colonne 'Nom' en 'Libelle'\n",
    "    df_exemples = df_exemples.rename(columns={'Nom': 'Libelle'})\n",
    "\n",
    "    # Calculer le temps de traitement\n",
    "    end = time.time()\n",
    "    runtime = end - start\n",
    "\n",
    "    # Afficher le DataFrame\n",
    "    if df_exemples is not None and not df_exemples.empty:\n",
    "        print(f\"DataFrame créé avec succès au bout de : {runtime:.2f} secondes.\")\n",
    "        \n",
    "        # Afficher toutes les colonnes\n",
    "        pd.set_option('display.max_columns', None)    \n",
    "        print(df_exemples.head())\n",
    "        \n",
    "        # Sauvegarder le DataFrame Explorateur [Exemples] en fichier JSON\n",
    "        df_exemples.to_json(json_output_path, orient='records', lines=True)\n",
    "        print(\"\\nDataFrame sauvegardé en fichier json, avec succès.\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Échec de la création du DataFrame ou DataFrame vide.\")\n",
    "    \n",
    "    return df_exemples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3a2d2d-e05a-487a-951c-3f90c9475918",
   "metadata": {},
   "source": [
    "|                                    | \n",
    "|:--:                                |\n",
    "| [(Retour au sommaire)](#summaryUp) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24a3f61-4127-4f54-82b3-6b0c8a085803",
   "metadata": {},
   "source": [
    "#### <a name=\"tbm-04-02\" />Récolter les données de l'Explorateur Ecobalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a1ceb96-a1c7-4ff1-ab34-9e699ff43645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les informations relatives à ces exemples de textiles sont disponibles depuis le lien :\n",
      "https://fabrique-numerique.gitbook.io/ecobalyse/textile/exemples\n",
      "\n",
      "Récupérer les données de l'Explorateur Ecobalyse ...\n",
      "DataFrame créé avec succès au bout de : 5.47 secondes.\n",
      "                                             Libelle      Categorie   ecs  \\\n",
      "0  Tshirt coton (150g) - Chine - Mode \"fast fashion\"  Tshirt / Polo  1162   \n",
      "1  Tshirt synthétique (150g) - Asie - Mode \"ultra...  Tshirt / Polo  1191   \n",
      "2          Tshirt coton (150g) - Majorant par défaut  Tshirt / Polo  1851   \n",
      "3        Tshirt lin (150g) - France - Mode \"éthique\"  Tshirt / Polo   419   \n",
      "4  Tshirt coton bio (150g) - France - Mode \"éthique\"  Tshirt / Polo   482   \n",
      "\n",
      "           Pays                       Mode  Masse      Matiere  \n",
      "0         Chine        Mode \"fast fashion\"   0.15        coton  \n",
      "1          Asie  Mode \"ultra fast fashion\"   0.15  synthétique  \n",
      "2  Pays inconnu        Majorant par défaut   0.15        coton  \n",
      "3        France             Mode \"éthique\"   0.15          lin  \n",
      "4        France             Mode \"éthique\"   0.15    coton bio  \n",
      "\n",
      "DataFrame sauvegardé en fichier json, avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Récupérer les données de l'Explorateur Ecobalyse via get_ecobalyse_datas()\n",
    "url = 'https://ecobalyse.beta.gouv.fr/#/explore/textile'\n",
    "columns = ['Nom', 'Categorie', 'ecs', 'pef', '.']\n",
    "json_output_path = 'data/PRJ-ECOBALYSE-01-WEB_SCRAPING1_temp1.json'\n",
    "df = get_ecobalyse_datas(url, columns, json_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b79a6f-ad95-42fe-a32a-b69b03fdfee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Libelle</th>\n",
       "      <th>Categorie</th>\n",
       "      <th>ecs</th>\n",
       "      <th>Pays</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Masse</th>\n",
       "      <th>Matiere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tshirt coton (150g) - Chine - Mode \"fast fashion\"</td>\n",
       "      <td>Tshirt / Polo</td>\n",
       "      <td>1162</td>\n",
       "      <td>Chine</td>\n",
       "      <td>Mode \"fast fashion\"</td>\n",
       "      <td>0.15</td>\n",
       "      <td>coton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tshirt synthétique (150g) - Asie - Mode \"ultra...</td>\n",
       "      <td>Tshirt / Polo</td>\n",
       "      <td>1191</td>\n",
       "      <td>Asie</td>\n",
       "      <td>Mode \"ultra fast fashion\"</td>\n",
       "      <td>0.15</td>\n",
       "      <td>synthétique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tshirt coton (150g) - Majorant par défaut</td>\n",
       "      <td>Tshirt / Polo</td>\n",
       "      <td>1851</td>\n",
       "      <td>Pays inconnu</td>\n",
       "      <td>Majorant par défaut</td>\n",
       "      <td>0.15</td>\n",
       "      <td>coton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tshirt lin (150g) - France - Mode \"éthique\"</td>\n",
       "      <td>Tshirt / Polo</td>\n",
       "      <td>419</td>\n",
       "      <td>France</td>\n",
       "      <td>Mode \"éthique\"</td>\n",
       "      <td>0.15</td>\n",
       "      <td>lin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tshirt coton bio (150g) - France - Mode \"éthique\"</td>\n",
       "      <td>Tshirt / Polo</td>\n",
       "      <td>482</td>\n",
       "      <td>France</td>\n",
       "      <td>Mode \"éthique\"</td>\n",
       "      <td>0.15</td>\n",
       "      <td>coton bio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Libelle      Categorie   ecs  \\\n",
       "0  Tshirt coton (150g) - Chine - Mode \"fast fashion\"  Tshirt / Polo  1162   \n",
       "1  Tshirt synthétique (150g) - Asie - Mode \"ultra...  Tshirt / Polo  1191   \n",
       "2          Tshirt coton (150g) - Majorant par défaut  Tshirt / Polo  1851   \n",
       "3        Tshirt lin (150g) - France - Mode \"éthique\"  Tshirt / Polo   419   \n",
       "4  Tshirt coton bio (150g) - France - Mode \"éthique\"  Tshirt / Polo   482   \n",
       "\n",
       "           Pays                       Mode  Masse      Matiere  \n",
       "0         Chine        Mode \"fast fashion\"   0.15        coton  \n",
       "1          Asie  Mode \"ultra fast fashion\"   0.15  synthétique  \n",
       "2  Pays inconnu        Majorant par défaut   0.15        coton  \n",
       "3        France             Mode \"éthique\"   0.15          lin  \n",
       "4        France             Mode \"éthique\"   0.15    coton bio  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b322c91-7ca5-445c-9293-06aef4bf4749",
   "metadata": {},
   "source": [
    "<a name=\"anchorDown\" />\n",
    "\n",
    "##### PROJET : Impact Textile avec EcoBalyse - Récolte des données\n",
    "\n",
    "|                                          |                               |\n",
    "|:--:                                      |:--:                           |\n",
    "| [(Retour au sommaire)](#summaryUp)  | [(Aller au début)](#anchorUp) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
